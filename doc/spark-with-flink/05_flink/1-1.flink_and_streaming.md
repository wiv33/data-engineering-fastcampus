# 1-1. apache flink

2009년 개발 시작

## 특징

- 오픈소스 스트림 프로세싱
- 분산처리, 고성능, 고가용성
    - in-memory
    - clustering
- 배치 프로세싱 지원
- Spark보다 빠른 속도
- Fault-tolerance
    - 시스템 장애 시 장애 직전으로 돌아가서 다시 시작할 수 있다.
- 활발한 개발
    - 그래프 프로세싱, 머신러닝, 텍스트 처리 등 라이브러리 지원
    - 여러가지 라이브러리와 프레임워크와 연동 가능
- Rescalability
    - 실행 도중 리소스 추가 가능

## 진행 방식

- 스스트림 프로세싱 파이프라인 만들기
- flink 상태 관리법
- 이벤트 분석
- 이벤트 드리븐 어플리케이션 만들기 - with kafka
- `fault-tolerant`하고 확장성 있는 스트림 프로세싱

# 1-2. Stream processing

## batch vs stram

### batch processing

- 비교적 무거운 데이터를 특정 주기적인 처리
- 한정된 데이터를 다룰 때 사용
- 모든 데이터 셋을 읽은 후 처리 가능
- 처리 속도보다 처리량에 중점을 둔다.

### stram processing

- 비교적 가벼운 데이터를 실시간 처리를 목적
- 무한한 데이터라고 가정
- 실시간으로 실행되는 작업
- 처리량보다 처리 속도체 중점을 둔다.

## 언제 쓰이는지

- 주식 거래소
- 웹 서버
- 센서 데이터 처리
- 이벤트 드리븐 어플리케이션
    - db -> db
    - 유저에게 실시간 알람
    - MSA 내 데이터 ingest 시 여러 서비스에 publish 작업할 때 사용
- 비정상 거래 탐지

## 기본적인 처리 구조

Streaming Data Flow

- Sources
    - 한개 혹은 여러 개의 데이터 소스가 있을 수 있다.
- Operators
    - 데이터를 변환 (transformation)
    - window 개념 지원
- Sink
    - 데이터 플로우의 마지막 출력 또는 저장하는 단계
        - application
        - event log

내부적으로 check point 개념을 가지고 있음

# 1-3. Hadoop vs Spark vs flink

## Hadoop

- batch processing
- disk에서 데이터 읽고 처리

    input (Mapper) -> 상태 1 (Mapper disk) -> Reducer -> output

### 데이터 처리

- 데이터 처리 방법을 손수 코딩
- 낮은 단계의 추상화

## Spark

- batch processing
- batch based Streaming
- in-memory

            transformation (in-memory)
      input ->   상태 1   ->   상태 2   -> output

### 데이터 처리

- 높은 단계의 추상화
- 쉬운 프로그래밍
- RDD

### library

- MLlib
- ...

## flink

- stream processing
- in-memory

               transformation (in-memory)
      input ->   상태 1   ->     상태 2     -> output

### 데이터 처리

- 높은 단계의 추상화
- 쉬운 프로그래밍
- DataFlows

### library

- flinkML
- ...

## Spark vs Flink 개발 비교

### spark

- scala로 개발
- 효율적인 메모리 관리가 어렵다
- OOM 에러가 자주 발생
- 의존성 관리로 DAG 사용

### flink

- java로 개발
- 내장 메모리 매니저
- OOM 에러가 자주 안 난다.
- Controlled cyclic dependency graph (ML 같이 반복적인 작업에 최적화)

# 1-4. flink 구성과 생태계

Flink 특징

- 클러스터를 이루고, 100만 단위의 이벤트 처리
- Latency가 1초 이하 (sub-second)
- Exactly-once 보장
    - 1번 이상의 처리를 보장
- 정확한 결과를 보장

## flink 구성

### storage

각종 저장 시스템들과 연동이 가능하도록 설계됨.

- HDFS
- local file system
- mongo db
- RDBMS (MySQL, Postgres)
- S3
- Rabbit MQ

### deployment

리소스 관리도 여러 시스템과 연동하여 사용 가능

- local
- Standalone cluster
- yarn
- mesos
- AWS / GCP (cloud)

### flink 구성

- Stateful Stream Processing
    - DataStream  (stream)
    - DataSet API (batch - deprecated)
        - Table API (테이블이 다이나믹하게 변경되도록 지원)
            - SQL (join 및 groupBy 등의 API 지원, `가장 높은 단계 추상화`)

### flink connector

**source & sink**

- apache kafka (sink / source)
- RabbitMQ (sink / source)
- amazone kinesis (sink / source)

**source**

- Twitter Streaming API (source)

**sink**

- HDFS (sink)
- elasticsearch (sink)
- apache Cassandra (sink)
- redis (sink)

### third party project
- apache zepplin
  - 웹 베이스 노트북
- apache mahout
  - 머신러닝 라이브러리
- cascading
  - workflows 매니지먼트
- apache Beam
  - data pipeline 생성 및 관리 툴
  - flink를 backend로 사용하고 있음.


### flink api 의존성

의존 방향 구조
    
    |      JVM        |     |         | 
    |       or        | <-  | Flink   |  <- DataSet     <-  Relational CEP       <- Zepplin
    | Cluster Manager |     | Runtime |  <- DataStream  <-  Relational Graph ML  <- Zepplin
                       

# 1-5. Flink 프로그래밍

## 프로그래밍 모델

    Source -> operations transformations -> sink

분산된 환경에서 독립적인 여러 이벤트들의 `sink`를 맞추는 것이 `flink`


# 1-6. Stateful Stream Processing

## state - 상태를 가지는 flink

event 각각을 독립적으로 처리하는 경우, `state`가 필요 없다.

Stateful
- 독립적인 event들의 집합을 확인할 수 있다.
- `checkpoints`와 `savepoints`로 `state`를 저장해서 내결함성을 갖도록 설계 
- queryable state를 이용해서 밖에서 `state`를 `관찰`할 수 있다.

### DataStream AIP 사용 케이스

- window로 데이터 모아보기
- transformations (key-value state)
- `CheckpointedFunction`으로 로컬 변수를 `fault tolerant(내결함성)`하게 만들기

### 활용 가능한 state backend

`HashmapStateBackend`
- java heap에 저장
- Hash table에 변수와 trigger를 저장
- 큰 state, 긴 windows, 큰 key/value 쌍을 저장할 때 권장
- 고가용성 환경
- 메모리 사용으로 빠른 처리

`EmbeddedRocksDBStateBackend`
- RocksDB에 저장
- 데이터는 byte array로 직렬화되어 저장
- 매우 큰 state, 긴 window, 큰 key/value state 저장
- 고가용성 환경
- Disk와 Serialize 사용으로 성능 / 처리량 tradeoff 필요

### Keyed State
- key - value store
- keyed stream에서만 이용 가능
- ex)
  - 각 이벤트가 id, value 스키마를 가지는 상황에서 
  - 각 id마다 value를 더하고 싶은 경우 keyed store를 사용

### State 저장

(장애) 결함이 생겼을 경우 저장된 `checkpoint`로 되돌아간다.

장애 허용을 가능하게 해주는 기능
- stream replay
- Checkpointing

checkpoint를 얼마나 자주 저장해야 하나?
- trade off
- 가벼운 state를 가진 프로그램은 자주 저장해도 된다.


분산된 데이터 스트림에서 생성하는 snapshot
- chandy-lamport 알고리즘
- 비동기적으로 실행

### Barriers
- 데이터를 시간별로 나누는 barrier를 삽입해 snapshot이 가능하다.
- barrier는 가볍게 설게되어 스트림이 방해되지 않는다.
- Sink operator가 barrier를 받아서 새로운 checkpoint를 만든다.

### Snapshot


### checkpoint 정렬
- 데이터가 오는대로 받아들여 체크포인트 만들기
- 빠른 속도를 위한 프로그램을 만ㄷ르 때 사용

### Recovery
- 장애 발생 시 마지막 체크포인틀르 불러온다.
- 시스템은 dataflow 전체를 re-deploy 한다.
- 각 operator에게 체크포인트의 state 정보를 주입한다.
- 입력 stream도 체크포인트일때로 돌려놓는다.
- 재시작
- kafka의 상태도 되돌릴 수 있기 때문에 궁합이 잘 맞는다.

### Savepoints
- 사용자가 지정한 체크포인트
- 다른 체크포인트처럼 자동으로 없어지지 않는다.

### Exactly once vs at least once

분산 환경에서 체크포인트 정렬 여부
- 정렬한 경우 `Exactly once`
- 하지 않은 경우 `at least once`

속도가 중요할 경우 `at least once` 사용


# 1-7. Timely Stream processing
데이터에 시간 개념이 적용되어 있을 때, 분산된 환경에서 pc마다 시간이 다른 경우
- Time Series Analysis
- Windows
- Event time이 중요할 때

## Time 종류
- processing time
- event time

### Processing time
데이터를 처리하는 시스템의 시간 기준

- Hourly time window
  - 9:15분 시스템 시작
  - 9:15 ~ 10:00
  - 10:00 ~ 11:00
- 가장 빠른 성능과 Low Latency
- 분산되고 비동기적인 환경에서는 결정적(deterministic) 이지 못하다.
  - 이벤트가 시스템에 도달하는 속도에 달렸기 때문이다.

### Event time

flink에 도달하기 전에 이벤트 시간을 생성.

- event가 생성된 곳에서 만들어진 시간 활용
- Flink에 도달하기 전 이벤트 자체에 기록 보관
- 시간은 시스템이 아니라 data 자체에 의존
- 이벤트 타임 프로그램은 `Event Time Watermark를 생성`해야 한다.


### watermark : 두 Time processing

이벤트 시간의 흐름을 재는 개념.

최소한 watermark 위치까지 읽었다고 표시하는 방법.

- Event time에 의존하는 시스템은 시간의 프름을 재는 방법이 따로 필요하다.
  - ex) 1시간짜리 window operation 이면 1시간이 흘렀다는 것을 알아야 한다.
- Event time과 Processing time은 싱크가 안 맞을 수 있다.
  - ex) 1주짜리 데이터를 몇 초 만에 계산할 수 있다.

순서대로 오지 못한 데이터는  적어도 watermark 까지 수신했다는 의미.

여러 input strea을 받는 operator 경우, `가장 이른 event time`을 사용한다.

### Lateness event
window는 time 기반일 수 있고, 데이터 기반일 수 있다.

window time 10분 기반
- 10분에 10개 또는 10분에 1000개가 유입될 수 있다.

window data 10개 기반
- 데이터 10개의 도착이 1초일 수도, 1시간일 수도 있다.


# 1-8. flink architecture

분산시스템으로 컴퓨팅 리소스 분배가 효율적이어야 한다.
- yarn
- kubernetes


## Flink Clutter

Flink Program에서 JobManager에 제출, JobManager가 TaskManager에 업무 할당


### Job Manager

- Task 스케줄링 (다음 task가 언제 실행될 지)
- 실패/완료된 tasks 관리
- 체크포인트 관리
- 실패 시 Recovery

#### 컴포넌트
1. Resource manager - task slot 관리
2. Dispatcher - Flink app을 등록하는 REST API & Web UI
3. JobMaster - 1개이ㅡ JobGraph 관리


### Task manager

- Aka workers
- Dataflow의 task를 실행하는 주체
- Task slot - 태스크 매니저를 스케줄링하는 가장 작은 단위
- Task slot으로 동시에 실행될 수 있는 tasks 설정

#### Task Worker
JVM 프로세스

- 여러 쓰레드에서 하나 혹은 여러 개의 sub task를 실행 가능
- `Task Slot`은 하나의 TaskManager가 가질 수 있는 `Task 수`를 `조절`한다.

# 1-9. pyflink

2019년 8월 Table API와 베터 버전

2020년 apache flink에서 다운로드 가능


## `python` - data science와 가장 가까운 언어

apache flink 위에 올려진 python api

파이썬으로 스트림 프로세싱을 할 수 있다.

`Py4J`로 자바 코드 변환이 이루어진다.



# 1-10. install flink

## 구조

conf - 사용자 정의 설정

opt - third party lib

plugins

...


## install flink
```bash
mkdir $HOME/flink
cd $HOME/flink

wget https://dlcdn.apache.org/flink/flink-1.16.0/flink-1.16.0-bin-scala_2.12.tgz
tar xzf flink-1.16.0
```

## install apache-flink

```bash
pip install apache-flink
```

## example 실행

```bash
./bin/flink run examples/streaming/WordCount.jar
```

# 1-11. word counting

## cluster start
```bash
./bin/start-cluster.sh
```


## example word count
```bash
./bin/flink run examples/streaming/WordCount.jar
```

## example python

```bash
./bin/flink run --python examples/python/datastream/word_count.py
```

## web ui

```bash
open -a firefox localhost:8081
```


## mini cluster 실행

python file을 생성하듯 명령어를 입력하면, mini cluster로 실행해준다.

```bash
python examples/python/datastream/word_count.py

cat examples/python/datastream/word_count.py
```